{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f5b2b3-9bc2-494f-abb2-22d9216f3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json\n",
    "import joblib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ddee2-9473-4192-bbde-d7aa89854ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e6244-585f-4126-a21e-bc9c0f97cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5edaae-9e36-4608-b357-96396da4cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded1b87-793e-4a99-8f4f-1908a4715a68",
   "metadata": {},
   "source": [
    "# Check loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26325cd-1672-4970-9e8a-d254d4b38a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350b2ed-5243-4631-958a-71f699d2a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d2983d-0486-4ec5-9f0d-1dab5db40de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "loss_ce = nn.CrossEntropyLoss().to(device)\n",
    "loss_bce = nn.BCELoss().to(device)\n",
    "\n",
    "# Assume input and target are tensors\n",
    "input = torch.randn(3, 5, requires_grad=True).to(device)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5c4d55-805c-4f4d-aa22-89abe0c12005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba583c6-9445-45e4-81a6-455515668cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss\n",
    "loss = loss_ce(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e36e5-6f03-4200-9e68-e33b41f4f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca77412a-6e4e-45b0-be41-af58c62e72ce",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddf7b5e-e30e-478b-88ae-1fcc500e7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './Data'\n",
    "subset = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3e33a-0efe-4ab4-bf94-c62f30381de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('labels_100_image.json')\n",
    "json_content = f.read()\n",
    "json_strings = json_content.split('\\n')\n",
    "data = [json.loads(js) for js in json_strings if js]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb3796-7efa-4248-9a76-5027fdeeedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_object_sample = joblib.load(f\"{DATA_DIR}/VisualPredFeatures_b5/119.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064e19f-73f2-413d-b8f1-1a0a0219d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_object_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c93f7-98bb-4e84-986b-c21748013fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, caption, label = df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a44f8-5f54-4738-b192-4d1d51afab3e",
   "metadata": {},
   "source": [
    "# Test data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1141f3ee-9d43-4b3b-b466-121d3c5f6e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6d7dfd-81bb-467d-a4d8-866bc6c8ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Data/train_160000/label_file_train_160000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43e42392-7f0c-45b3-b3dd-c664924565e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>caption_id</th>\n",
       "      <th>context_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105726</th>\n",
       "      <td>14161.jpg</td>\n",
       "      <td>105922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name  caption_id  context_label\n",
       "105726  14161.jpg      105922              1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f08ac2a-d072-4dd0-932f-05585522baaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': \"[CLS] The Adani Group's Mundra power station, India's largest private coal fired power plant, under construction in the state of Gujarat.[SEP] The Adani Group's Patrick Kearns power station, which is the biggest private coal fired power plant in Sea Cliff, is under construction in Cumberland state.[SEP]\",\n",
       " 'rels': [[['station', 'under', 'construction'],\n",
       "   ['state', 'of', 'gpe'],\n",
       "   ['construction', 'in', 'state']],\n",
       "  [['which', 'be', 'plant'],\n",
       "   ['plant', 'in', 'gpe'],\n",
       "   ['construction', 'in', 'state']]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps_data_train[105922]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aafe5201-8b9c-4e84-92ac-e68026984f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[7000:8500].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d57bd4-4ea4-4207-8ee2-0f3ee3c64c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>caption_id</th>\n",
       "      <th>context_label</th>\n",
       "      <th>match_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83103.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31819.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155454.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38395.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97259.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70258</th>\n",
       "      <td>105249.jpg</td>\n",
       "      <td>70258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70259</th>\n",
       "      <td>92475.jpg</td>\n",
       "      <td>70259</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70260</th>\n",
       "      <td>82709.jpg</td>\n",
       "      <td>70260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70261</th>\n",
       "      <td>103831.jpg</td>\n",
       "      <td>70261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70262</th>\n",
       "      <td>15331.jpg</td>\n",
       "      <td>70262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name  caption_id  context_label  match_label\n",
       "0       83103.jpg           0              0            0\n",
       "1       31819.jpg           1              0            0\n",
       "2      155454.jpg           2              0            0\n",
       "3       38395.jpg           3              0            0\n",
       "4       97259.jpg           4              0            0\n",
       "...           ...         ...            ...          ...\n",
       "70258  105249.jpg       70258              1            0\n",
       "70259   92475.jpg       70259              1            0\n",
       "70260   82709.jpg       70260              1            0\n",
       "70261  103831.jpg       70261              1            0\n",
       "70262   15331.jpg       70262              1            0\n",
       "\n",
       "[70263 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf1866e7-8519-4846-b009-f22046cd1d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bf6348-9cb6-4396-9d3a-0786e6cfbbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takhu\\anaconda3\\envs\\crawl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\takhu\\anaconda3\\envs\\crawl\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from data_utils import *\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "305f2b24-ecb4-4955-8386-c6b156b5e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJ_FT_DIR = './Data/train_10000/VisualObjectFeatures' # run extract_visual_features.py to get this\n",
    "PRED_FT_DIR = './Data/train_10000/VisualPredFeatures' # run extract_visual_features.py to get this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2204704-eabf-4391-8dee-800952643422",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './Data'\n",
    "subset = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "134f7c2c-17da-4f7c-8106-2681b09ee37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_data_train = joblib.load(f\"{DATA_DIR}/train_160000/cheapfake_train_lowered_caps_data_160000.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a56093-bb0c-47e1-8d21-1c56812adf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_data_train = joblib.load(f\"{DATA_DIR}/train_80000/cheapfake_train_lowered_caps_data_80000.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a2580d-a286-4d1e-83c8-f6bc4d247ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': ['\"I was wondering if it would sound normal. Like, I\\'m screaming my brains out in an empty gym. But it fits,\" said Matt Pitman, a public-address announcer inside the W.N.B.A. bubble.',\n",
       "  '&ldquo;I was wondering if it would sound normal. Like, I&rsquo;m screaming my brains out in an empty gym. But it fits,&rdquo; said Matt Pitman, a public-address announcer inside the W.N.B.A. bubble.'],\n",
       " 'rels': [[['i', 'in', 'gym'],\n",
       "   ['announcer', 'inside', 'bubble'],\n",
       "   ['i', 'scream', 'brain']],\n",
       "  [['quo', 'scream', 'brain'],\n",
       "   ['announcer', 'inside', 'bubble'],\n",
       "   ['quo', 'in', 'gym']]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps_data_train[random.randint(0,60000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a088f293-46bb-4b3c-b410-64d7c44e425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_sentence(sentence):\n",
    "    # split the sentence by the special token [SEP]\n",
    "    sentence = sentence.replace(\"[CLS] \", \"\")\n",
    "    sentences = sentence.split(\"[SEP]\") \n",
    "    # remove the leading and trailing spaces from each sentence\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    # remove the empty sentences\n",
    "    sentences = [s for s in sentences if s]\n",
    "    # return the list of sentences\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1b33820-6968-41e8-9aea-e4618d9ccf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Representative Elissa Slotkin, a Democrat in a Republican-leaning district in Michigan, has resisted calls to impeach President Trump.',\n",
       " 'Representative Elissa Slotkin, a Democrat in a Republican-leaning district in Michigan, has resisted calls to impeach President Trump.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separate_sentence(caps_data_train[random.randint(0,60000)]['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b118b8d6-62bb-42fe-b6fa-972c88c957c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': '[CLS] A billboard in Tehran depicting General Suleimani, left, and an Iraqi official in charge of militias and close to Iran, Abu Mahdi al Muhandis, who was also killed in the drone strike.[SEP] A billboard in Tehran depicting General Suleimani, left, and an Iraqi official in charge of militias and close to Iran, Abu Mahdi al Muhandis, who was also killed in the drone strike.[SEP]',\n",
       " 'rels': [[['charge', 'of', 'militia'],\n",
       "   ['official', 'depict', 'norp'],\n",
       "   ['billboard', 'depict', 'norp'],\n",
       "   ['official', 'in', 'charge'],\n",
       "   ['official', 'in', 'gpe'],\n",
       "   ['billboard', 'in', 'gpe']],\n",
       "  [['charge', 'of', 'militia'],\n",
       "   ['official', 'depict', 'norp'],\n",
       "   ['billboard', 'depict', 'norp'],\n",
       "   ['official', 'in', 'charge'],\n",
       "   ['official', 'in', 'gpe'],\n",
       "   ['billboard', 'in', 'gpe']]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "caps_data_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f956276-9b2f-45ee-8971-9b67c07ee227",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(caps_data_train)):\n",
    "    caps_data_train[i]['sent'] = separate_sentence(caps_data_train[i]['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90da1465-9b5c-4096-a53a-a8348d589d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': ['A billboard in Tehran depicting General Suleimani, left, and an Iraqi official in charge of militias and close to Iran, Abu Mahdi al Muhandis, who was also killed in the drone strike.',\n",
       "  'A billboard in Tehran depicting General Suleimani, left, and an Iraqi official in charge of militias and close to Iran, Abu Mahdi al Muhandis, who was also killed in the drone strike.'],\n",
       " 'rels': [[['charge', 'of', 'militia'],\n",
       "   ['official', 'depict', 'norp'],\n",
       "   ['billboard', 'depict', 'norp'],\n",
       "   ['official', 'in', 'charge'],\n",
       "   ['official', 'in', 'gpe'],\n",
       "   ['billboard', 'in', 'gpe']],\n",
       "  [['charge', 'of', 'militia'],\n",
       "   ['official', 'depict', 'norp'],\n",
       "   ['billboard', 'depict', 'norp'],\n",
       "   ['official', 'in', 'charge'],\n",
       "   ['official', 'in', 'gpe'],\n",
       "   ['billboard', 'in', 'gpe']]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps_data_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6ed0555-e925-49c7-9508-66b50941be27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Data/train_160000/cheapfake_train_lowered_caps_data_160000.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(caps_data_train, f\"{DATA_DIR}/train_160000/cheapfake_train_lowered_caps_data_160000.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aec0535d-79d3-4ccf-97db-02edf94fffc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caps_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cd8b651-0a53-4840-9cf0-e1c66dc48700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps_data_train[101113]['sent'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4edfb0-ead0-4d4d-8295-878bd9c85f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70263"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caps_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db2b906d-8847-491d-b0ba-462b7cc125f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sent': \"[CLS] Sri Lanka killings: Channel 4 reports 'unlikely to be faked'[SEP] Sri Lanka judge says war crimes claims are 'credible'[SEP]\", 'rels': [[['reports', 'is', 'faked'], ['reports', 'on', 'killings'], ['reports', 'on', 'org']], [['judge', 'says', 'judgement'], ['claims', 'is', 'crimes'], ['judge', 'is', 'gpe)'], ['claims', 'is', 'credible']]]}\n",
      "{'sent': '[CLS] While the rest of the city enjoyed an unseasonably mild start to the new year, with nary a flake in sight, the crew of \"Home Alone 2: Lost in New York\" whipped up a fake blizzard in front of the Plaza Hotel off 5th Avenue. Jan. 8, 1992.[SEP] While the rest of the city enjoyed an unseasonably mild start to the new year, with nary a flake in sight, the crew of “Home Alone 2: Lost in New York” whipped up a fake blizzard in front of the Plaza Hotel off 5th Avenue. Jan. 8, 1992.[SEP]', 'rels': [[['rest', 'enjoy', 'start'], ['rest', 'with', 'flake'], ['rest', 'of', 'city'], ['art', 'whip', 'blizzard'], ['rest', 'enjoy', 'date'], ['blizzard', 'in front', 'fac'], ['start', 'to', 'date'], ['flake', 'in', 'sight']], [['rest', 'enjoy', 'start'], ['rest', 'with', 'flake'], ['rest', 'of', 'city'], ['art', 'whip', 'blizzard'], ['rest', 'enjoy', 'date'], ['blizzard', 'in front', 'fac'], ['start', 'to', 'date'], ['flake', 'in', 'sight']]]}\n",
      "{'sent': '[CLS] Indian authorities are struggling to deal with inflammatory messages that spread on social platforms. They shut down the entire internet in 2017 in the state of Punjab just before a popular spiritual guru was convicted on rape charges. That did not stop his followers from flooding the streets, and at least 30 people died in the violence.[SEP] Exposing fake news before it spreads is a herculean task in India, where an estimated quarter of a billion people use social media[SEP]', 'rels': [[['that', 'on', 'platform'], ['they', 'in', 'state'], ['people', 'in', 'violence'], ['they', 'in', 'date'], ['that', 'stop', 'follower'], ['they', 'shut', 'internet'], ['state', 'of', 'norp']], [['cardinal', 'use', 'medium'], ['task', 'in', 'gpe']]]}\n",
      "{'sent': '[CLS] We had an unusual about turn with the front page picture last week with the Babchenko story, he was the Russian journalist who faked his own death with the help of the Ukrainian secret service. On that day there were pictures around of protesters attaching photographs of Babchenko to the gates of the Russian Embassy in Kiev, it was a front page story but they weren’t good enough front page pictures. When images from the press conference started to come in where he appeared alive, we had an unbelievable story and a great picture to go with it.[SEP] We had an unusual about turn with the front page picture last week with the Babchenko story, he was the Russian journalist who faked his own death with the help of the Ukrainian secret service. On that day there were pictures around of protesters attaching photographs of Babchenko to the gates of the Russian Embassy in Kiev, it was a front page story but they weren’t good enough front page pictures. When images from the press conference started to come in where he appeared alive, we had an unbelievable story and a great picture to go with it.[SEP]', 'rels': [[['picture', 'go with', 'it'], ['photograph', 'of', 'person'], ['turn', 'with', 'page'], ['protester', 'attach', 'photograph'], ['they', 'be', 'picture'], ['who', 'with', 'help'], ['image', 'from', 'conference'], ['gate', 'of', 'org'], ['protester', 'to', 'gate'], ['it', 'be', 'story'], ['we', 'have', 'picture'], ['who', 'fake', 'death'], ['help', 'of', 'service'], ['we', 'have', 'story'], ['gate', 'in', 'gpe'], ['he', 'be', 'journalist'], ['picture', 'with', 'story']], [['picture', 'go with', 'it'], ['photograph', 'of', 'person'], ['turn', 'with', 'page'], ['protester', 'attach', 'photograph'], ['they', 'be', 'picture'], ['who', 'with', 'help'], ['image', 'from', 'conference'], ['gate', 'of', 'org'], ['protester', 'to', 'gate'], ['it', 'be', 'story'], ['we', 'have', 'picture'], ['who', 'fake', 'death'], ['help', 'of', 'service'], ['we', 'have', 'story'], ['gate', 'in', 'gpe'], ['he', 'be', 'journalist'], ['picture', 'with', 'story']]]}\n",
      "{'sent': \"[CLS] A woman sits wearing fake handcuffs under a sign that reads 'police station'[SEP] A woman sits wearing fake handcuffs under a sign that reads ‘police station’[SEP]\", 'rels': [[['that', 'read', 'station']], [['that', 'read', 'station']]]}\n",
      "{'sent': \"[CLS] Zar's fake papers identifying her as Wanda Gajda.[SEP] Zar’s fake papers identifying her as Wanda Gajda.[SEP]\", 'rels': [[['paper', 'identify', 'she'], ['paper', 'as', 'person']], [['paper', 'identify', 'she'], ['paper', 'as', 'person']]]}\n",
      "{'sent': '[CLS] Israeli truck drivers wait inside a bomb shelter at Kerem Shalom crossing August 1, 2014.[SEP] Hamas shoots Israeli drone, triggering fake sirens in Jewish settlements[SEP]', 'rels': [[['driver', 'inside', 'shelter'], ['shelter', 'at', 'person']], [['siren', 'in', 'settlement']]]}\n",
      "{'sent': '[CLS] The demonstrators say they collected 17 million signatures -- roughly 4 million more than what won Morsy the presidency -- and all of them call for Morsy to go.[SEP] Picture No. 11 - Abeer Sabry Lafarfash: My video of my abuse of the Rabaa Al-Adawiya protesters is fake[SEP]', 'rels': [[['what', 'win', 'person'], ['they', 'collect', 'signature']], [['abuse', 'of', 'protester'], ['video', 'of', 'abuse']]]}\n",
      "{'sent': '[CLS] Supporters wait for President Donald Trump to deliver remarks at the NRA Leadership Forum at the Georgia World Congress Center in Atlanta, Georgia, April 28, 2017.[SEP] Supporters of President Donald Trump wait for him to deliver remarks at the National Rifle Association Leadership Forum in Atlanta, Georgia, on April 28. Political operatives used fake news, Big Data and Facebook to suppress the vote and rile up racists in 2016.[SEP]', 'rels': [[['remark', 'at', 'org'], ['remark', 'at', 'fac'], ['person', 'deliver', 'remark']], [['operative', 'use', 'news'], ['remark', 'at', 'org'], ['racist', 'in', 'date'], ['he', 'on', 'date'], ['he', 'deliver', 'remark'], ['operative', 'use', 'org'], ['supporter', 'of', 'person']]]}\n",
      "{'sent': \"[CLS] BBC's Human Planet in a fakery series on staged tree houses[SEP] Watch the world | Douban scored 9.8 BBC epic documentary exposed to fake[SEP]\", 'rels': [[['series', 'on', 'house']], [['ban', 'score', 'documentary']]]}\n",
      "{'sent': '[CLS] A carefully crafted, controversial fake video, said Representative Adam B. Schiff, the chairman of the Intelligence Committee, would be \"hugely disruptive and hugely influential.\"[SEP] A carefully crafted, controversial fake video, said Representative Adam B. Schiff, the chairman of the Intelligence Committee, would be “hugely disruptive and hugely influential.”[SEP]', 'rels': [[['chairman', 'of', 'org']], [['chairman', 'of', 'org']]]}\n",
      "{'sent': '[CLS] how to tell authentic canada goose jackets[SEP] Canada Goose toronto sale fake - RCMP seize Canada Goose jacket with raccoon dog fur trim ...[SEP]', 'rels': [[['jackets', 'is', 'gpe'], ['jackets', 'is', 'authentic'], ['jackets', 'is', 'goose']], [['sale', 'seize', 'jacket'], ['jacket', 'with', 'trim']]]}\n",
      "{'sent': \"[CLS] Sri Lanka killings: Channel 4 reports 'unlikely to be faked'[SEP] Sri Lanka judge says war crimes claims are 'credible'[SEP]\", 'rels': [[['reports', 'is', 'faked'], ['reports', 'on', 'killings'], ['reports', 'on', 'org']], [['judge', 'says', 'judgement'], ['claims', 'is', 'crimes'], ['judge', 'is', 'gpe)'], ['claims', 'is', 'credible']]]}\n",
      "{'sent': '[CLS] Activists for Christian aid charity World Vision, wearing masks of G8 leaders, carry fake sacks of money in their recreation of \"The Italian Job\" in Rome July 6, 2009.[SEP] Co-ordination is key to G8 success[SEP]', 'rels': [[['mask', 'of', 'leader'], ['sack', 'of', 'money'], ['recreation', 'of', 'art'], ['activist', 'in', 'recreation'], ['activist', 'carry', 'sack'], ['recreation', 'in', 'date'], ['activist', 'for', 'org']], [['ordination', 'kept', 'success'], ['ordination', 'is', 'key'], ['success', 'is', 'g8']]]}\n",
      "{'sent': '[CLS] Facebook identified a range of fake accounts pushing information about American and Philippine politics and Chinese activity in the South China Sea. [SEP] Facebook identified a range of fake accounts pushing information about American and Philippine politics and Chinese activity in the South China Sea.[SEP]', 'rels': [[['range', 'of', 'account'], ['account', 'push', 'information'], ['facebook', 'identify', 'range'], ['information', 'about', 'politic'], ['information', 'about', 'norp']], [['range', 'of', 'account'], ['account', 'push', 'information'], ['facebook', 'identify', 'range'], ['information', 'about', 'politic'], ['information', 'about', 'norp']]]}\n",
      "{'sent': '[CLS] President Trump during a news conference on Friday at the White House. \"It\\'s a fake story and it\\'s a disgrace that they\\'re allowed to do it,\" he told reporters earlier in the Oval Office, referring to the Atlantic article.[SEP] President Trump during a news conference on Friday at the White House.\\xa0“It’s a fake story and it’s a disgrace that they’re allowed to do it,” he told reporters earlier in the Oval Office, referring to the Atlantic article.[SEP]', 'rels': [[['he', 'in', 'fac'], ['conference', 'on', 'date'], ['it', 'be', 'story'], ['it', 'be', 'disgrace'], ['date', 'at', 'fac'], ['he', 'tell', 'reporter']], [['he', 'in', 'fac'], ['conference', 'on', 'date'], ['it', '’', 'story'], ['it', '’', 'disgrace'], ['date', 'at', 'fac'], ['he', 'tell', 'reporter']]]}\n",
      "{'sent': '[CLS] A woman shouts slogans through a megaphone during a march to mark the International Day for Elimination of Violence against Women in Lima November 25, 2009.[SEP] Facebook’s new anti-fake news strategy is not going to work – but something else\\xa0might[SEP]', 'rels': [[['woman', 'during', 'date'], ['woman', 'shout', 'slogan'], ['woman', 'through', 'megaphone']], [['news', 'is', 'strategy'], ['news', 'is', 'org'], ['news', 'is', 'fake'], ['news', 'is', 'new']]]}\n",
      "{'sent': '[CLS] This morning, the Melbourne police fired several shots at two clowns in the City! Just because the other party brought a fake gun[SEP] At the &quot;Wife Swapping Party&quot; in Australia, someone in clown clothes had sex in public! Pointing at the police &quot;with a gun&quot;![SEP]', 'rels': [[['police', 'at', 'cardinal'], ['police', 'fire', 'shot'], ['cardinal', 'in', 'city'], ['party', 'bring', 'gun']], [['someone', 'have', 'sex'], ['someone', 'in', 'public'], ['someone', 'at', 'swapping'], ['someone', 'at', 'wife'], ['someone', 'in', 'gpe']]]}\n",
      "{'sent': '[CLS] Sandra Diaz said she was undocumented when she worked at the golf club from 2010 to 2013.[SEP] Illegal: Sandra Diaz worked at the Trump National Golf Club in Bedminster, N.J.   and still has the uniform   despite gaining the role with a fake green card[SEP]', 'rels': [[['she', 'from', 'date'], ['she', 'at', 'club'], ['she', 'to', 'date']], [['role', 'with', 'card'], ['person', 'at', 'org'], ['person', 'in', 'gpe']]]}\n",
      "{'sent': \"[CLS] A supporter of Egypt's former army chief Abdel Fattah al-Sisi wears a fake knife over his head in front of an Egyptian flag as he celebrates at Tahrir square in Cairo May 28, 2014.[SEP] The people of Egypt expect social and economic problems to be solved.[SEP]\", 'rels': [[['knife', 'over', 'head'], ['he', 'at', 'fac'], ['supporter', 'wear', 'knife'], ['supporter', 'of', 'person']], [['people', 'of', 'gpe']]]}\n",
      "{'sent': \"[CLS] Planet Earth 2: Viewers complain about 'fake' sound effects despite BBC explaining the technology isn't available[SEP] A shot from Planet Earth II[SEP]\", 'rels': [[['effect', 'despite', 'org'], ['effect', 'explain', 'technology']], [['shot', 'from', 'loc']]]}\n",
      "{'sent': '[CLS] A tourist bus makes its way past an empty building, which has been covered with artwork to make it look more appealing, in the village of Bushmills on the Causeway Coast August 20, 2013.[SEP] A tourist bus makes its way past an empty building, which has been covered with artwork to make it look more appealing, in the village of Bushmills on the Causeway Coast August 20, 2013. One of the homes of Irish whiskey has taken a scheme developed in Northern Ireland of erecting fake shop fronts where derelict buildings lie and has truly run with it in a bid to woo tourists. Bushmills, best known as the village where the whiskey of the same name was distilled for the first time 400 years ago, is now also becoming recognizable for the artwork and graphics that brighten up shop fronts left empty during the economic downturn. Picture taken August 20, 2013[SEP]', 'rels': [[['way', 'past', 'building'], ['village', 'of', 'mills'], ['bus', 'make', 'way']], [['that', 'brighten', 'front'], ['bid', 'woo', 'tourist'], ['mill', 'as', 'village'], ['way', 'past', 'building'], ['home', 'of', 'whiskey'], ['whiskey', 'of', 'name'], ['mill', 'for', 'artwork'], ['picture', 'take', 'date'], ['village', 'of', 'mills'], ['scheme', 'in', 'gpe'], ['mill', 'for', 'graphic'], ['cardinal', 'take', 'scheme'], ['bus', 'make', 'way'], ['front', 'during', 'downturn']]]}\n",
      "{'sent': '[CLS] President Trump during a news conference on Friday at the White House. \"It\\'s a fake story and it\\'s a disgrace that they\\'re allowed to do it,\" he told reporters earlier in the Oval Office, referring to the Atlantic article.[SEP] President Trump during a news conference on Friday at the White House.\\xa0“It’s a fake story and it’s a disgrace that they’re allowed to do it,” he told reporters earlier in the Oval Office, referring to the Atlantic article.[SEP]', 'rels': [[['he', 'in', 'fac'], ['conference', 'on', 'date'], ['it', 'be', 'story'], ['it', 'be', 'disgrace'], ['date', 'at', 'fac'], ['he', 'tell', 'reporter']], [['he', 'in', 'fac'], ['conference', 'on', 'date'], ['it', '’', 'story'], ['it', '’', 'disgrace'], ['date', 'at', 'fac'], ['he', 'tell', 'reporter']]]}\n",
      "{'sent': '[CLS] Sandra Diaz said she was undocumented when she worked at the golf club from 2010 to 2013.[SEP] Illegal: Sandra Diaz worked at the Trump National Golf Club in Bedminster, N.J.   and still has the uniform   despite gaining the role with a fake green card[SEP]', 'rels': [[['she', 'from', 'date'], ['she', 'at', 'club'], ['she', 'to', 'date']], [['role', 'with', 'card'], ['person', 'at', 'org'], ['person', 'in', 'gpe']]]}\n",
      "{'sent': '[CLS] Facebook identified a range of fake accounts pushing information about American and Philippine politics and Chinese activity in the South China Sea. [SEP] Facebook identified a range of fake accounts pushing information about American and Philippine politics and Chinese activity in the South China Sea[SEP]', 'rels': [[['range', 'of', 'account'], ['account', 'push', 'information'], ['facebook', 'identify', 'range'], ['information', 'about', 'politic'], ['information', 'about', 'norp']], [['range', 'of', 'account'], ['account', 'push', 'information'], ['facebook', 'identify', 'range'], ['information', 'about', 'politic'], ['information', 'about', 'norp']]]}\n",
      "{'sent': \"[CLS] An anti-government protester looks at Istanbul's Taksim square June 5, 2013.[SEP] Podcast: fake news, how to defend yourself?[SEP]\", 'rels': [[['protester', 'at', 'date']], [['news', 'is', 'defend'], ['news', 'is', 'fake']]]}\n",
      "{'sent': \"[CLS] A supporter of Egypt's former army chief Abdel Fattah al-Sisi wears a fake knife over his head in front of an Egyptian flag as he celebrates at Tahrir square in Cairo May 28, 2014.[SEP] A supporter of Egypt's former army chief Abdel Fattah al-Sisi wears a fake knife over his head in front of an Egyptian flag as he celebrates at Tahrir square in Cairo May 28, 2014.[SEP]\", 'rels': [[['knife', 'over', 'head'], ['he', 'at', 'fac'], ['supporter', 'wear', 'knife'], ['supporter', 'of', 'person']], [['knife', 'over', 'head'], ['he', 'at', 'fac'], ['supporter', 'wear', 'knife'], ['supporter', 'of', 'person']]]}\n",
      "{'sent': \"[CLS] Sri Lanka killings: Channel 4 reports 'unlikely to be faked'[SEP] Sri Lankan Opposition slams UNHRC resolution[SEP]\", 'rels': [[['reports', 'is', 'faked'], ['reports', 'on', 'killings'], ['reports', 'on', 'org']], [['person', 'slam', 'resolution']]]}\n",
      "{'sent': \"[CLS] A woman sits wearing fake handcuffs under a sign that reads 'police station'[SEP] Holidays in the Brazilian women&#39;s prison[SEP]\", 'rels': [[['that', 'read', 'station']], [['holiday', 'in', 'prison']]]}\n",
      "{'sent': \"[CLS] Duan Peng, a Chinese student, runs online shops on Alibaba. Here, he answers customers' questions while eating lunch in the School of Entrepreneurship of Yiwu Industrial and Commercial College in Yiwu, China.[SEP] Alibaba&#39;s Jack Ma once promised to expand the global trade of small businesses around the world through the development of e-commerce. However, the proliferation of fakes and plagiarism on the Taobao platform has hit small business owners in the United States. Sherwin/European Pressphoto Agency[SEP]\", 'rels': [[['shop', 'on', 'gpe'], ['person', 'run', 'shop'], ['lunch', 'in', 'org'], ['he', 'answer', 'question']], [['development', 'of', '-'], ['business', 'around', 'world'], ['development', 'of', 'e'], ['proliferation', 'of', 'fake'], ['development', 'of', 'commerce'], ['trade', 'of', 'business'], ['proliferation', 'hit', 'owner'], ['proliferation', 'on', 'platform'], ['proliferation', 'of', 'plagiarism'], ['proliferation', 'in', 'gpe']]]}\n",
      "{'sent': '[CLS] Activists for Christian aid charity World Vision, wearing masks of G8 leaders, carry fake sacks of money in their recreation of \"The Italian Job\" in Rome July 6, 2009.[SEP] Co-ordination is key to G8 success[SEP]', 'rels': [[['mask', 'of', 'leader'], ['sack', 'of', 'money'], ['recreation', 'of', 'art'], ['activist', 'in', 'recreation'], ['activist', 'carry', 'sack'], ['recreation', 'in', 'date'], ['activist', 'for', 'org']], [['ordination', 'kept', 'success'], ['ordination', 'is', 'key'], ['success', 'is', 'g8']]]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    sample = df.loc[i]\n",
    "    if sample['context_label'] == 1:\n",
    "        continue\n",
    "    caption_id = sample['caption_id']\n",
    "    caption = caps_data_train[caption_id]\n",
    "    sentence = caption['sent']\n",
    "    if \"fake\" in sentence:\n",
    "        print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a99902ee-3fcb-4ab0-aaec-156c53aeaa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': '[CLS] Soubry warns May will lose final Brexit vote unless she changes course[SEP] Anna Soubry accuses Tory constituency chair of plotting to get rid of her with false claims of Brexit clashes[SEP]',\n",
       " 'rels': [[['date', 'lose', 'vote']],\n",
       "  [['person', 'accuse', 'chair'], ['claim', 'of', 'clash']]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'sent': '[CLS] Soubry warns May will lose final Brexit vote unless she changes course[SEP] Anna Soubry accuses Tory constituency chair of plotting to get rid of her with false claims of Brexit clashes[SEP]', 'rels': [[['date', 'lose', 'vote']], [['person', 'accuse', 'chair'], ['claim', 'of', 'clash']]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eecb0217-84a9-4768-9e44-b78355cf9f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': '[CLS] Evacuees from Buzi village carry their belongings as they arrive at the displacement center near the airport, after Cyclone Idai, in Beira, Mozambique, March 25.[SEP] The ride-hailing company had set an initial price range last month of $44 to $50 a share.[SEP]',\n",
       " 'rels': [[['evacuee', 'carry', 'belonging'],\n",
       "   ['center', 'near', 'airport'],\n",
       "   ['evacuee', 'from', 'village'],\n",
       "   ['evacuee', 'after', 'person'],\n",
       "   ['they', 'at', 'center']],\n",
       "  [['date', 'of', 'money'], ['company', 'set', 'date']]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps_data_train[8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e609bc17-b1d1-4772-9ada-89aaebf097e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data_train = joblib.load(f\"{DATA_DIR}/train_16000/cheapfake_train_lowered_images_data_16000.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3f45f9b-f549-4603-8c1f-77e0983ca59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2idx_cap = joblib.load(f\"../NewData/flickr30k_caps_word2idx.joblib\") # This dictionary include the above\n",
    "word2idx_cap = joblib.load(f\"{DATA_DIR}/train_16000/cheapfake_lowered_caps_word2idx_train_16000.joblib\")\n",
    "word2idx_img_obj = joblib.load(f\"{DATA_DIR}/flickr30k_lowered_img_obj_word2idx.joblib\")\n",
    "word2idx_img_pred = joblib.load(f\"{DATA_DIR}/flickr30k_lowered_img_pred_word2idx.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe94e6-3474-4c78-92a6-8ee4b81ea1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2idx_img_pred.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8192910-48f7-40ae-b840-001d291000d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2idx_img_obj.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b71d3-527c-4dfc-b5a1-e540723fed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2idx_cap.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f93adc-b4a4-4234-8866-8823a60d6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_embed_model_weight_cap = joblib.load(f'{DATA_DIR}/init_glove_embedding_weight_lowered_train_70000.joblib')\n",
    "init_embed_model_weight_cap = torch.FloatTensor(init_embed_model_weight_cap)\n",
    "init_embed_model_weight_img_obj = joblib.load(f'{DATA_DIR}/init_glove_embedding_weight_lowered_img_obj.joblib')\n",
    "init_embed_model_weight_img_obj = torch.FloatTensor(init_embed_model_weight_img_obj)\n",
    "init_embed_model_weight_img_pred = joblib.load(f'{DATA_DIR}/init_glove_embedding_weight_lowered_img_pred.joblib')\n",
    "init_embed_model_weight_img_pred = torch.FloatTensor(init_embed_model_weight_img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0969c59-6fb8-47db-a8e2-7cd64e28414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_embed_model_weight_cap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b469cda-5ec3-4126-9b9f-eade7a24a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(init_embed_model_weight_img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7886cbab-b0ab-41f0-826e-cf2b5b96ae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/train_10000/VisualPredFeatures\n"
     ]
    }
   ],
   "source": [
    "datatrain = PairGraphPrecomputeDataset(image_sgg=images_data_train, caption_sgg=caps_data_train,\n",
    "                                                    word2idx_cap=word2idx_cap, tokenizer=tokenizer, word2idx_img_obj=word2idx_img_obj,\n",
    "                                                    word2idx_img_pred=word2idx_img_pred, effnet='b5',\n",
    "                                                    samples=df, obj_ft_dir=OBJ_FT_DIR, pred_ft_dir=PRED_FT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "465486bf-c798-423e-871b-2ae709ccf919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name       65003.jpg\n",
       "caption_id            8000\n",
       "context_label            1\n",
       "Name: 985, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[985]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153f356-877f-4bc3-b74c-6059709886a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data_test = joblib.load(f\"{DATA_DIR}/cheapfake_{subset}_lowered_images_data.joblib\")\n",
    "caps_data_test = joblib.load(f\"{DATA_DIR}/cheapfake_{subset}_lowered_caps_data.joblib\")\n",
    "df_test = pd.read_csv(f\"{DATA_DIR}/label_file_{subset}.csv\")\n",
    "OBJ_FT_DIR_test = f\"{DATA_DIR}/{subset}/VisualObjectFeatures\" # run extract_visual_features.py to get this\n",
    "PRED_FT_DIR_test = f\"{DATA_DIR}/{subset}/VisualPredFeatures\" # run extract_visual_features.py to get this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337f7b4a-5393-4b7c-a244-ee2474537d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest = PairGraphPrecomputeDataset(image_sgg=images_data_test, caption_sgg=caps_data_test,\n",
    "                                                    word2idx_cap=word2idx_cap, tokenizer=tokenizer, word2idx_img_obj=word2idx_img_obj,\n",
    "                                                    word2idx_img_pred=word2idx_img_pred, effnet='b5',\n",
    "                                                    samples=df_test, obj_ft_dir=OBJ_FT_DIR_test, pred_ft_dir=PRED_FT_DIR_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "115aac40-fae6-494f-92a2-b112e9aacb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent': '[CLS] Evacuees from Buzi village carry their belongings as they arrive at the displacement center near the airport, after Cyclone Idai, in Beira, Mozambique, March 25.[SEP] The ride-hailing company had set an initial price range last month of $44 to $50 a share.[SEP]',\n",
       " 'rels': [[['evacuee', 'carry', 'belonging'],\n",
       "   ['center', 'near', 'airport'],\n",
       "   ['evacuee', 'from', 'village'],\n",
       "   ['evacuee', 'after', 'person'],\n",
       "   ['they', 'at', 'center']],\n",
       "  [['date', 'of', 'money'], ['company', 'set', 'date']]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capid = 8000\n",
    "datatrain.caption_sgg[capid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c089ea-0c06-445b-a5b7-731a07855432",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_cap[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7888b-98e4-4dcd-be7d-c64769edb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_sentence, cap_sent_np, cap_mask = encode_caption_sgg_to_matrix(sgg=datatrain.caption_sgg[capid], \n",
    "                                                                    word2idx=datatrain.word2idx_cap, tokenizer=datatrain.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef1f04-d564-4cef-8a3b-273e24745c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain.image_sgg[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5005019-b2fe-422f-ad17-81c3ebf9d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_obj_np, img_pred_np, img_edge_np = encode_image_sgg_to_matrix(sgg=datatrain.image_sgg[\"36.jpg\"],\n",
    "                                                                    word2idx_obj=datatrain.word2idx_img_obj,\n",
    "                                                                    word2idx_pred=datatrain.word2idx_img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4819a-739a-4efc-83a7-52f62373ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1935d-77d9-4031-b2fa-d49b05643098",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a43748-808a-4af2-80dd-1293b643bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = datatrain.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1382559-d12d-403b-860d-b29e46be64a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed5e52-5d3e-4af7-9a5e-65343a9f76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_object_sample = joblib.load(\"VisualObjectFeatures_b5/65567.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9643c38-4142-455f-85f8-e79ea8165ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_object_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43875267-a84d-4cb0-8f96-9b80adf68649",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloadertrain = make_PairGraphPrecomputeDataLoader(datatrain, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1f85773-94de-4f08-bb61-53c326d36ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = [(batchID, batch) for batchID, batch in enumerate(dataloadertrain)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a461a8-d8aa-478f-9138-52a2a8a46cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst[0][1][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6fa35-61c8-4da2-9305-8aeae2afd889",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloadertrain = make_PairGraphPrecomputeDataLoader(datatrain, batch_size=2, shuffle=False)\n",
    "lst = [(batchID, batch) for batchID, batch in enumerate(dataloadertrain)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490c393-eb24-40dc-a060-03d6c5090e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloadertest = make_PairGraphPrecomputeDataLoader(datatest, batch_size=1, shuffle=False)\n",
    "lst_test = [(batchID, batch) for batchID, batch in enumerate(dataloadertest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ba6f897-5795-4c03-9e69-2f5f8136cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = lst[985][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6026959a-7ec2-4fde-a5b4-2890c78b1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p_o, img_p_o_ft, img_p_p, img_p_p_ft, img_p_e, img_p_numb_o, img_p_numb_p,\\\n",
    "            cap_p_o_1, cap_p_p_1, cap_p_e_1, cap_p_numb_o_1, cap_p_numb_p_1, cap_p_len_p_1,\\\n",
    "            cap_p_o_2, cap_p_p_2, cap_p_e_2, cap_p_numb_o_2, cap_p_numb_p_2, cap_p_len_p_2,\\\n",
    "            cap_p_s, cap_p_m, cap_p_len_s, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd3e9e-9397-48ec-ab9b-6dddce7cce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p_o, img_p_o_ft, img_p_p, img_p_p_ft, img_p_e, img_p_numb_o, img_p_numb_p,\\\n",
    "            cap_p_o, cap_p_p, cap_p_e, cap_p_numb_o, cap_p_numb_p, cap_p_len_p, cap_p_s, cap_p_m, cap_p_len_s, labels = lst[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117070e6-1cd0-4b4c-91c8-ef8c598490ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec1070-e749-4e29-af63-25c41c9a6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e332a-c030-43c6-9ac5-bc1cab4c8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_len_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c38a9-7bda-4af6-85ba-6d8972231be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cap_p_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee1e96-dced-434b-b0ab-d28301f7ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cap_p_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf1266-3e61-4273-893a-b5fc66abd9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_numb_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bdb02e-c76b-465d-84a1-2bc773424e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_numb_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2a4c257-bec9-4550-ab41-1a67fcbafc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model = check_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd5fb72f-8c09-4f3c-8aaa-149a53c496a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_objects_1, eb_cap_edges_1 = check_model.feature_extraction.cap_branch_model(cap_p_p_1, cap_p_e_1, cap_p_len_p_1, cap_p_numb_o_1, cap_p_numb_p_1)#cap_p_p_2, cap_p_e_2, cap_p_len_p_2, cap_p_numb_o_2, cap_p_numb_p_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b548707e-8692-47f7-81c0-2a1371ca0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_geb_1 = check_model.feature_extraction.graph_embed_model(eb_cap_objects_1, eb_cap_edges_1, cap_p_numb_o_1, cap_p_numb_p_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1dcb7fa-136c-4387-a8fb-7eb77761b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_objects_2, eb_cap_edges_2 = check_model.feature_extraction.cap_branch_model(cap_p_p_2, cap_p_e_2, cap_p_len_p_2, cap_p_numb_o_2, cap_p_numb_p_2)#cap_p_p_2, cap_p_e_2, cap_p_len_p_2, cap_p_numb_o_2, cap_p_numb_p_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1686b57b-e4ba-4537-9a7b-25a5831a90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_geb_2 = check_model.feature_extraction.graph_embed_model(eb_cap_objects_2, eb_cap_edges_2, cap_p_numb_o_2, cap_p_numb_p_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af4ca68f-44ab-4ec5-8d77-f10f4c4b971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "                img_p_o_ft = img_p_o_ft.to(device)\n",
    "                img_p_p_ft = img_p_p_ft.to(device)\n",
    "                img_p_o = img_p_o.to(device)\n",
    "                img_p_p = img_p_p.to(device) \n",
    "                img_p_e = img_p_e.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db9dff95-3cee-4758-8547-aee0d406c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_image_objects, gcn_image_predicates = check_model.feature_extraction.image_branch_model(img_p_o_ft, img_p_p_ft, img_p_o, img_p_p, img_p_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b648b0a7-08ee-4928-be62-8bdb5d5ecc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_geb = check_model.feature_extraction.graph_embed_model(gcn_image_objects, gcn_image_predicates, img_p_numb_o, img_p_numb_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80fef85d-825c-4290-b5fa-a1825bc2c99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0160,  0.0129, -0.0148,  ..., -0.0212, -0.0244, -0.0061]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_geb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5c12f52-31e8-47bb-940f-dbb0b1a558cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9435], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine = torch.nn.functional.cosine_similarity(image_geb, caption_geb_1)\n",
    "cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e87c8-6776-431e-846a-fd2b9b8d0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_len_p_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898370c-13b7-46d9-b27b-6aec5c35d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_e_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c1c29-351a-4bdc-a180-1f1c861496dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cap_p_p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8baffd-b9a1-4efa-9508-e806560ff307",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_p_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe7216-2ee9-4ec0-a7bd-9c8e014b5e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_e_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d0421-2900-4fe5-9e26-f3ac8a32fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_len_p_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a61a1a-9417-4526-a405-b7f5a6bcaec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_numb_o_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67f0ab-7377-4af6-8971-58f616bb65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_numb_p_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebfcec-c095-4b25-983c-787d740a23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model.feature_extraction.cap_branch_model(cap_p_p_2, cap_p_e_2, cap_p_len_p_2, cap_p_numb_o_2, cap_p_numb_p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6688a-e32d-4bee-9325-fc7e42e120b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_geb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71fd99-bda8-47b7-9655-5068e8dbb8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_objects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db19e10-64b7-4ebe-b6e8-e7bc15a458ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448966aa-5bd8-45df-a249-77cdf54103cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_objects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99cbcf1-2518-4159-90e7-605d2c957e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14512e4a-8d5d-4e9e-9f3f-f67b6c70af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979a278-431a-4490-9ce5-2d1b59970795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "                total_cap_p_numb_o = sum(cap_p_numb_o)\n",
    "                total_cap_p_numb_p = sum(cap_p_numb_p)\n",
    "                eb_cap_objects = torch.zeros(total_cap_p_numb_o, check_model.feature_extraction.cap_branch_model.gcn_output_dim).to(device)\n",
    "                eb_cap_edges = torch.zeros(total_cap_p_numb_p, check_model.feature_extraction.cap_branch_model.gcn_output_dim).to(device)\n",
    "                if total_cap_p_numb_p > 0:\n",
    "                    cap_predicates = pad_sequence(cap_p_p, batch_first=True)\n",
    "                    embed_cap_predicates = check_model.feature_extraction.cap_branch_model.embed_model_cap(cap_predicates.to(device))\n",
    "                    rnn_eb_cap_p_rels, rnn_eb_cap_p_rels_nodes =  check_model.feature_extraction.cap_branch_model.rels_model(embed_cap_predicates, cap_p_len_p)\n",
    "                    for idx in range(len(rnn_eb_cap_p_rels_nodes)):\n",
    "                        edge = cap_p_e[idx] # subject, object\n",
    "                        eb_cap_objects[edge[0]] = rnn_eb_cap_p_rels_nodes[idx,1,:] # <start> is 1st token\n",
    "                        eb_cap_objects[edge[1]] = rnn_eb_cap_p_rels_nodes[idx,cap_p_len_p[idx]-2 ,:] # <end> is last token\n",
    "                        eb_cap_edges[idx] = torch.mean(rnn_eb_cap_p_rels_nodes[idx,2:(cap_p_len_p[idx]-2),:], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311732a-cadc-471a-8ea8-834024cbf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09fa8f-6f08-444b-97bd-1ca9a86d3bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_objects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf8c02-0f29-4ea3-b368-10b6ccf45814",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rnn_eb_cap_p_rels_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbd4a63-87a2-4871-b5b9-a1576c5f6b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205541d-b19a-48b5-8198-10674fd89bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e405233-b02c-43bd-9f9f-ab436250e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_predicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5de2b24-edfe-4fde-b6c4-ce97721ce98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cap_predicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9265d5c-3158-4836-8f45-c4a19539370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_eb_cap_p_rels_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264cede3-c27f-4b42-a20a-424911a126f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_objects, eb_cap_edges = check_model.feature_extraction.gcn_model_cap(eb_cap_objects, eb_cap_edges, cap_p_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d2cd9-b5a3-4a08-97bb-b85e99447787",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_objects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06353579-389d-4519-af7b-08d66770c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_geb = check_model.feature_extraction.graph_embed_model(eb_cap_objects, eb_cap_edges, cap_p_numb_o, cap_p_numb_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36595b-1f87-4a63-9486-b69af9ba4cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_geb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd8e8d-bbbf-441d-9d51-bd01314961ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model.feature_extraction.gcn_output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba869f9-b393-4b85-83ae-7c399652c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b820762-6ce1-47df-8e5d-48600c384276",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_len_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7edf67-df70-42f5-8e16-c93981b6f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bcef8e-ffdf-4c86-8bf8-5f46cfc6fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = lst[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c13b9-3397-4232-9ee4-06e3bc169a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205837d-c879-4145-b3d8-1e7ec3662079",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p_o, img_p_o_ft, img_p_p, img_p_p_ft, img_p_e, img_p_numb_o, img_p_numb_p,\\\n",
    "            cap_p_o, cap_p_p, cap_p_e, cap_p_s, cap_p_m, cap_p_numb_o, cap_p_numb_p, cap_p_len_p, cap_p_len_s, labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5785af3-375a-476f-a401-d3d4bb9921e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p_o_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12265a-ed37-4a49-83a0-ae0f90c3f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c31bf-6590-4c83-8ace-83ff309c4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p_numb_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa31ea3-d4a0-49c8-acfa-05f0fd72f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_p_numb_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b60b930-28a4-4949-9da3-8e9929dd74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2af88-2b61-4f5e-8493-a8d6307af93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_numb_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9151e92b-5b67-49cc-86cc-a12ea5226022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "X = pad_sequence(cap_p_p, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f9e8a-46a3-48ff-a98e-52d5fc9ca0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lengths = [len(sentence) for sentence in cap_p_s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfa7351-1c27-4e22-873e-c5acb2b622be",
   "metadata": {},
   "source": [
    "# Check models_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf55777-8c20-42b4-bdd5-4b8eca74e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6104e2e-a4ac-4969-9496-82f2e85b82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CAP_WORDS = len(word2idx_cap)\n",
    "TOTAL_IMG_OBJ = len(word2idx_img_obj)\n",
    "TOTAL_IMG_PRED = len(word2idx_img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041b31c-7026-4efa-8093-68480a762134",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = dict()\n",
    "info_dict['save_dir'] = './Report'\n",
    "\n",
    "info_dict['total_img_obj'] = TOTAL_IMG_OBJ\n",
    "info_dict['total_img_pred'] = TOTAL_IMG_PRED\n",
    "info_dict['total_cap_words'] = TOTAL_CAP_WORDS\n",
    "info_dict['numb_sample'] = None # training sample for 1 epoch\n",
    "info_dict['numb_epoch'] = 100 # number of epoch\n",
    "info_dict['numb_gcn_layers'] = 1 # number of gin layers to be stacked\n",
    "info_dict['gcn_hidden_dim'] = [] # hidden layer in each gin layer\n",
    "info_dict['gcn_output_dim'] = 1024 # graph embedding final dim\n",
    "info_dict['gcn_input_dim'] = 2048 # node and edges dim of a graph\n",
    "info_dict['batchnorm'] = True\n",
    "info_dict['batch_size'] = 128\n",
    "info_dict['dropout'] = 0.5\n",
    "info_dict['visual_backbone'] = 'b5' # EfficientNet backbone to extract visual features\n",
    "info_dict['visual_ft_dim'] = 2048\n",
    "info_dict['optimizer'] = 'Adam' # or Adam\n",
    "info_dict['learning_rate'] = 3e-4\n",
    "info_dict['activate_fn'] = 'swish' # swish, relu, leakyrelu\n",
    "info_dict['grad_clip'] = 2 # Gradient clipping\n",
    "# info_dict['use_residual'] = False # always set it to false (not implemented yet)\n",
    "# Embedder for each objects and predicates, embed graph only base on objects\n",
    "info_dict['model_name'] = 'GCN_ObjAndPredShare_NoFtExModule_LSTM' \n",
    "info_dict['checkpoint'] = None # Training from a pretrained path\n",
    "info_dict['margin_matrix_loss'] = 0.35\n",
    "info_dict['rnn_numb_layers'] = 2\n",
    "info_dict['rnn_bidirectional'] = True\n",
    "info_dict['rnn_structure'] = 'LSTM' # LSTM or GRU (LSTM gave better result)\n",
    "info_dict['graph_emb_dim'] = info_dict['gcn_output_dim']*2\n",
    "info_dict['include_pred_ft'] = True # include visual predicate features or not\n",
    "info_dict['freeze'] = False # Freeze all layers except the graph convolutional network and graph embedding module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148e123-7faa-49b0-aa6f-8cce58990470",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model = CheapFake_Detection(info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb06d48-0900-499a-881f-f9dcad6db13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model = check_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca289f-0957-425f-8206-1e96fa7500b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380186c-ed18-4481-9d7a-8774af262acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = check_model.feature_extraction.graph_embed_model\n",
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0967b81-be59-4c3a-bfca-5857e8d4d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_all_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32fb8b6-b1e0-4133-9531-5282bb3a5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model.feature_extraction.cap_branch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a7c01-fe97-42ea-ad3c-8fa336eaf9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model.feature_extraction.embed_model_cap.model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b01b82-7574-4f8c-aec1-47b3305f2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model.feature_extraction.mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55a275-d514-415c-a16e-c56693b81db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cap_p_numb_o = sum(cap_p_numb_o)\n",
    "total_cap_p_numb_p = sum(cap_p_numb_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d759e-4fac-4820-b79e-dbd586149b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_p_numb_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7107c9-50a6-4edd-a3a1-cb2721c53071",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_objects = torch.zeros(total_cap_p_numb_o, check_model.feature_extraction.gcn_output_dim)\n",
    "eb_cap_edges = torch.zeros(total_cap_p_numb_p, check_model.feature_extraction.gcn_output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb5173-fb4d-4974-94de-25a5741197ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_image_objects, gcn_image_predicates = check_model.feature_extraction.image_branch_model(img_p_o_ft, img_p_p_ft, img_p_o, img_p_p, img_p_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60096bdf-4b6f-4bbd-92f2-7e1c9ba2e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_geb = check_model.feature_extraction.graph_embed_model(gcn_image_objects, gcn_image_predicates, img_p_numb_o, img_p_numb_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae95b3-a43e-4b9f-8f92-34af03b127aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_geb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27212a-91dc-44db-8017-dd1bfd6d6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model.feature_extraction.gcn_model_cap(eb_cap_objects, eb_cap_edges, cap_p_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d8f0d-792e-4c05-9ce6-8d24d2d3cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "            img_p_o_ft = img_p_o_ft.to(device)\n",
    "            img_p_p_ft = img_p_p_ft.to(device)\n",
    "            img_p_o = img_p_o.to(device)\n",
    "            img_p_p = img_p_p.to(device) \n",
    "            img_p_e = img_p_e.to(device)\n",
    "            # cap_p_o = cap_p_o.to(device)\n",
    "            # cap_p_p = cap_p_p.to(device) \n",
    "            cap_p_e_1 = cap_p_e_1.to(device)\n",
    "            cap_p_e_2 = cap_p_e_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25c2c6-6e0e-407c-bb8b-7d572e4b129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(img_p_o_ft, img_p_p_ft, img_p_o, img_p_p, img_p_e, img_p_numb_o, img_p_numb_p, cap_p_s, cap_p_m, cap_p_p_1, cap_p_e_1, cap_p_len_p_1, cap_p_numb_o_1, cap_p_numb_p_1, cap_p_p_2, cap_p_e_2, cap_p_len_p_2, cap_p_numb_o_2, cap_p_numb_p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68225ed2-c686-4a0c-8253-14a86003c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for batch_id, batch in lst:\n",
    "    img_p_o, img_p_o_ft, img_p_p, img_p_p_ft, img_p_e, img_p_numb_o, img_p_numb_p,\\\n",
    "            cap_p_o, cap_p_p, cap_p_e, cap_p_s, cap_p_m, cap_p_numb_o, cap_p_numb_p, cap_p_len_p, cap_p_len_s, labels = batch\n",
    "    temp_predict = check_model(img_p_o_ft, img_p_p_ft, img_p_o, img_p_p, img_p_e, img_p_numb_o, img_p_numb_p, cap_p_s, cap_p_m, cap_p_p, cap_p_e, cap_p_len_p, cap_p_numb_o, cap_p_numb_p)\n",
    "    result.append(temp_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267dd4e-fc8f-4a9c-b0fc-d462d71cca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b2164-9728-4e40-a6ea-04c487ac1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_result = check_model(img_p_o_ft, img_p_p_ft, img_p_o, img_p_p, img_p_e, img_p_numb_o, img_p_numb_p, cap_p_s, cap_p_m, cap_p_p, cap_p_e, cap_p_len_p, cap_p_numb_o, cap_p_numb_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f169c0-1d64-4d68-8d55-bb2e0f43c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e365ad-814b-4052-bc3f-2f0d543e217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0855f3-26ca-4aac-82e5-e160743f77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bce = nn.BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c6c50-3bad-46e6-a536-3660147d5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_bce(check_result, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb8bb5-1b38-4d61-9599-677a59a84e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1984e-61e4-45e5-984a-343cd332c083",
   "metadata": {},
   "source": [
    "# Check models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0b919-d883-4d78-89a5-3e2ea667c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38136668-6613-4425-b150-0a6cf9c54d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CAP_WORDS = len(word2idx_cap)\n",
    "TOTAL_IMG_OBJ = len(word2idx_img_obj)\n",
    "TOTAL_IMG_PRED = len(word2idx_img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58843b33-557d-4b96-914f-d035e40a41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CAP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547fa330-b548-43f0-be05-cc0574502282",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_branch_model = ImageModel(word_unit_dim=300, gcn_output_dim=1024, \n",
    "                                          gcn_hidden_dim=[], numb_gcn_layers=1, \n",
    "                                          batchnorm=True, dropout=0.5, activate_fn='swish',\n",
    "                                          visualft_structure='b5', \n",
    "                                          visualft_feature_dim=2048, \n",
    "                                          fusion_output_dim=2048, \n",
    "                                          numb_total_obj=TOTAL_IMG_OBJ, numb_total_pred=TOTAL_IMG_PRED, \n",
    "                                          init_weight_obj=init_embed_model_weight_img_obj, \n",
    "                                          init_weight_pred=init_embed_model_weight_img_pred,\n",
    "                                          include_pred_ft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b39733-f20a-4f58-8e25-4f43310974e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_branch_model = image_branch_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2eb94f-2a69-4d9d-8fd1-95e678e7648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_image_objects, gcn_image_predicates = image_branch_model(img_p_o_ft, img_p_p_ft, img_p_o, img_p_p, img_p_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c5cd1-250e-4952-9e6e-da6c353196c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_image_predicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f387d6-de2a-49ad-96ac-885da8a67012",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_image_objects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b170ba1-a8f8-4161-9dd5-e51063cb4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2idx_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d74877-a20a-431a-b730-4b6a4f0d076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_embed_model_weight_cap = joblib.load(f'{DATA_DIR}/init_glove_embedding_weight_lowered_train_val.joblib')\n",
    "init_embed_model_weight_cap = torch.FloatTensor(init_embed_model_weight_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ca53a-6933-46d4-a2c8-caf88aeb4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_cap = WordEmbedding(numb_words=len(word2idx_cap), embed_dim=300, init_weight=init_embed_model_weight_cap, sparse=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5769ca3-28ce-4a16-a8b3-cb0cbfef6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_predicates = pad_sequence(cap_p_p, batch_first=True)\n",
    "embed_cap_predicates = embed_model_cap(cap_predicates.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a25b5c-5216-41f3-9416-7026f8cbdb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_cap_predicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39cc225-f5b0-46c1-981f-d400b362f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rels_model = RelsModel(input_dim=300, hidden_dim=1024 , \n",
    "                                       numb_layers=2, \n",
    "                                       dropout=0.5, bidirectional=True, \n",
    "                                       structure='LSTM').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133b213-e39d-4857-85d9-d84f8f058c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c266c-abf0-4b63-927c-a2743b43430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_eb_cap_p_rels, rnn_eb_cap_p_rels_nodes = rels_model(embed_cap_predicates, cap_p_len_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349208b-a155-4c47-b8bd-fde5c1ef29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_eb_cap_p_rels_nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a25c0-b211-4e75-99eb-46c3785961d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_eb_cap_p_rels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b43b6a-b42e-404f-a444-6af3cdc6b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model_cap = GCN_Network(gcn_input_dim=1024, gcn_pred_dim=1024, \n",
    "                                            gcn_output_dim=1024, gcn_hidden_dim=[], \n",
    "                                            numb_gcn_layers=1, batchnorm=True, \n",
    "                                            dropout=0.5,activate_fn='swish', use_residual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c42b3d-d412-4423-8164-3c6d5d3bb01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "            total_cap_p_numb_o = sum(cap_p_numb_o)\n",
    "            total_cap_p_numb_p = sum(cap_p_numb_p)\n",
    "            eb_cap_p_o = torch.zeros(total_cap_p_numb_o, 1024)\n",
    "            eb_cap_p_p = torch.zeros(total_cap_p_numb_p, 1024)\n",
    "            for idx in range(len(rnn_eb_cap_p_rels_nodes)):\n",
    "                edge = cap_p_e[idx] # subject, object\n",
    "                eb_cap_p_o[edge[0]] = rnn_eb_cap_p_rels_nodes[idx,1,:] # <start> is 1st token\n",
    "                eb_cap_p_o[edge[1]] = rnn_eb_cap_p_rels_nodes[idx,cap_p_len_p[idx]-2 ,:] # <end> is last token\n",
    "                eb_cap_p_p[idx] = torch.mean(rnn_eb_cap_p_rels_nodes[idx,2:(cap_p_len_p[idx]-2),:], dim=0)\n",
    "                #if cap_p_len_p[idx] > 5: # pred is longer than 1 words\n",
    "                #    eb_cap_p_p[idx] = torch.mean(rnn_eb_cap_p_rels_nodes[idx,2:(cap_p_len_p[idx]-2),:], dim=0)\n",
    "                #else:\n",
    "                #    eb_cap_p_p[idx] = rnn_eb_cap_p_rels_nodes[idx,2,:]\n",
    "            eb_cap_p_o, eb_cap_p_p = gcn_model_cap(eb_cap_p_o, eb_cap_p_p, cap_p_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a950c-8fe0-4b90-b516-3a9e3dc59fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_p_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686ce62-1ed5-4a90-b722-5365be1f21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_p_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf56b2-4d1c-4066-8bd9-5293a3541133",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_image_objects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e3874-d1aa-4fea-a82c-940c7df385f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_p_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507525bd-90d0-401d-a21e-f2e1e3f3c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_p_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83296d-a218-4c53-97ae-11d83b4f8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_embed_model = GraphEmb(node_dim=1024, edge_dim=1024,\n",
    "                                             fusion_dim=2048, activate_fn='swish', \n",
    "                                             batchnorm=True, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d0a13-847d-46fb-91e6-cc2db45327fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eb_cap_p_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d511b-8a9b-4ecd-be78-f77ecec17b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_geb = graph_embed_model(eb_cap_p_o, eb_cap_p_p, cap_p_numb_o, cap_p_numb_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd3221-544f-42b6-925d-34b5812f5149",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_geb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e307570-eb96-4bcd-b709-e1ff775426ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40449a-3ae0-46f1-9d06-4fac5b964695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b80599-eece-4b67-8cac-8aaf1f783c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentenceModel, self).__init__()\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")\n",
    "        self.deberta = model.deberta\n",
    "        self.pooler = model.pooler\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self.pooler(outputs.last_hidden_state)\n",
    "        # return a tensor of size 768\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd2670-4164-406e-ad86-534fbc266e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec9c1f-fc7a-4e69-b89f-24e048acd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1478505-6e43-4a02-8288-6aa9baf2d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"hihi haha\"\n",
    "sentence_2 = \"She is pregnant\"\n",
    "sentence_3 = \"She is not pregnant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9f2b3-e753-4708-bdbd-0e3b4b79d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [tokenizer(sentence, return_tensors=\"pt\")['input_ids'] for sentence in [sentence_1,sentence_2,sentence_3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b52bd-5653-43d7-9e74-2ef0b52ab87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sent = tokenizer(sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b4e5b-3888-4914-84e6-029b357fb275",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sentences = tokenizer([sentence_1,sentence_2,sentence_3], padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fcc20-4fa2-4a5b-b69a-fafea6c47a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a84347d-ebc2-4e18-99a8-75de42f1a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sentences['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3badcb-b239-4b78-afd5-1bbf14328009",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[ 1,  8595,  8080, 15731, 2],\n",
    "    [ 1,   503,   269,  4870,     2],\n",
    "    [ 1,   503,   269,   298,  4870,     2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c73bb-aa04-425f-b7bc-edf01f201b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensors = [torch.LongTensor(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455639c6-e7af-4c14-b253-fd3798478e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957e768-fa6d-4aad-a9c9-bb3db81258b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [[1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4400a71-a4ae-422f-98b1-6762a6c2195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tensors = [torch.tensor(y) for y in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5451c4-74a1-4264-a171-a8f509ed6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = pad_sequence(X_tensors, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bea9b-5f39-4ca7-9842-5a9602c2f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_padded = pad_sequence(Y_tensors, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4bc74-b987-4304-a4ee-2770acb7cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5082fd5-e308-4199-8ede-5defaaa06426",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc4214-f332-4190-ad8d-8838b86c30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f8a8d-c02e-4072-b08f-d25c624d4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.functional import pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca6248-2f1e-4cee-825d-d62b904e7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sequence(X, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b24b7-0a6f-4182-9b7f-cb174e5bc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b65572-96d3-4224-bfe8-d7971692c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51bfd38-3c65-487c-a498-ef190f67971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b5bd4-a6d2-4b08-a003-e528055e440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model(cap_p_s, cap_p_m).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff9367-cc7c-4d40-9dfc-f36318e8e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Hi there\", \"Rise of the kingdom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353125e-41b8-4627-8fb0-60782fd4826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sent = tokenizer(sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e4e06-2bd0-4357-af91-11ef549a1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(sentence_1, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51b11e-613e-45ae-bfc2-94f14ccd8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34289307-928b-4dc4-ad84-96ff33688cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c12c342-9c3f-481d-98c9-df500b022313",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1033a-4e70-4ad2-889b-445a0b809d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sent = sentence_model(input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348d360-1cd6-40a2-9117-1ddb39459645",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f114b2-20c3-431b-957d-9e0739db7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_p_numb_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0de0be-14b1-4a17-b4a3-f75c75093c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img_p_numb_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36dd85-4318-43a0-a2bf-db84ed473e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_geb = graph_embed_model(gcn_image_objects, gcn_image_predicates, img_p_numb_o, img_p_numb_p) # n_img, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce13ad-6176-4b8f-9be6-543c3d3af8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_geb = graph_embed_model(eb_cap_p_o, eb_cap_p_p, cap_p_numb_o, cap_p_numb_p) # n_cap, dim         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20bb814-3db3-48ea-a44f-78991786cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_geb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d1c50-5815-4e60-b321-7431ef4b8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_geb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b259d-425a-47a6-95f5-345ef27ea78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(input_dim=2048*2, \n",
    "                   hidden_dim=[2048,1024],\n",
    "                   output_dim=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f966e2-5edd-4eba-8257-be19f80dfe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = torch.cat([image_geb,caption_geb], dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889e5dd-a880-4898-868b-00a08c3e39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e981e7a-412a-466a-acbc-47ed16a6334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp(concat).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb11fb-41bc-4d8d-bc53-c42cb92c1954",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = []\n",
    "for batchID, batch in enumerate(dataloadertrain):\n",
    "  IDs.append(batchID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26e40f-45f5-49eb-8849-d878e2acf23d",
   "metadata": {},
   "source": [
    "# Test Controller_GCN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3f6278-8175-47d6-a88f-4797e9d1319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takhu\\anaconda3\\envs\\crawl\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Controller_GCN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092f7a13-f800-481c-a923-f61e3e79ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CAP_WORDS = len(word2idx_cap)\n",
    "TOTAL_IMG_OBJ = len(word2idx_img_obj)\n",
    "TOTAL_IMG_PRED = len(word2idx_img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04edc36d-71c1-4729-885a-2fd713ea2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = dict()\n",
    "info_dict['save_dir'] = './Report'\n",
    "\n",
    "info_dict['total_img_obj'] = TOTAL_IMG_OBJ\n",
    "info_dict['total_img_pred'] = TOTAL_IMG_PRED\n",
    "info_dict['total_cap_words'] = TOTAL_CAP_WORDS\n",
    "\n",
    "info_dict['numb_sample'] = None # training sample for 1 epoch\n",
    "info_dict['numb_epoch'] = 60 #100 # number of epoch\n",
    "info_dict['numb_gcn_layers'] = 1 # number of gin layers to be stacked\n",
    "info_dict['gcn_hidden_dim'] = [] # hidden layer in each gin layer\n",
    "info_dict['gcn_output_dim'] = 1024 # graph embedding final dim\n",
    "info_dict['gcn_input_dim'] = 2048 # node and edges dim of a graph\n",
    "info_dict['batchnorm'] = True\n",
    "info_dict['batch_size'] = 2 #128\n",
    "info_dict['dropout'] = 0.5\n",
    "info_dict['visual_backbone'] = 'b5' # EfficientNet backbone to extract visual features\n",
    "info_dict['visual_ft_dim'] = 2048\n",
    "info_dict['optimizer'] = 'Adam' # or Adam\n",
    "info_dict['learning_rate'] = 3e-4\n",
    "info_dict['activate_fn'] = 'swish' # swish, relu, leakyrelu\n",
    "info_dict['grad_clip'] = 2 # Gradient clipping\n",
    "# info_dict['use_residual'] = False # always set it to false (not implemented yet)\n",
    "# Embedder for each objects and predicates, embed graph only base on objects\n",
    "info_dict['model_name'] = 'GCN_ObjAndPredShare_NoFtExModule_LSTM' \n",
    "info_dict['checkpoint'] = None # Training from a pretrained path\n",
    "info_dict['margin_matrix_loss'] = 0.35\n",
    "info_dict['rnn_numb_layers'] = 2\n",
    "info_dict['rnn_bidirectional'] = True\n",
    "info_dict['rnn_structure'] = 'LSTM' # LSTM or GRU (LSTM gave better result)\n",
    "info_dict['graph_emb_dim'] = info_dict['gcn_output_dim']*2\n",
    "info_dict['include_pred_ft'] = True # include visual predicate features or not\n",
    "info_dict['freeze'] = False # Freeze all layers except the graph convolutional network and graph embedding module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab41b74b-3877-4e0e-a7e8-01dd264c4e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initilised with given init_weight\n",
      "Initilised with given init_weight\n",
      "Initilised with given init_weight\n"
     ]
    }
   ],
   "source": [
    "info_dict['checkpoint'] = './Report/GCN_Cheapfake_weights_12000.pth.tar'\n",
    "eval = Evaluator(info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cda1c02-c961-4781-89f1-0dd6c00f45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model = eval.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc6561f-980b-4c58-9566-4e05ad2f9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.model.MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b1548-2229-48bf-be79-4f0d96fccce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.model.MLP.numb_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24c8e8-78bb-4e64-b191-b1f41fd06497",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(eval.model.MLP.linear.modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b8868-83f2-47ef-a10c-e0a771f95fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = 2\n",
    "for name, param in eval.model.MLP.named_parameters():\n",
    "    if name not in [f'linear.{last_layer}.weight', f'linear.{last_layer}.bias']:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2f544-1f91-4564-b00b-13b0081283ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(eval.model.MLP.linear.parameters()):\n",
    "    print(i, layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4205f1-1dc5-440c-a8d7-5e560747c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(eval.model.MLP.parameters()):\n",
    "    #print(i, layer)\n",
    "    if i==9:\n",
    "        print(layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad16fba-718b-400f-a141-fb89caaf70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81999c0-cdc1-4e93-95a1-1330cdefc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    subset = 'test'\n",
    "    DATA_DIR = './Data'\n",
    "    images_data = joblib.load(f\"{DATA_DIR}/cheapfake_{subset}_lowered_images_data.joblib\")\n",
    "    caps_data = joblib.load(f\"{DATA_DIR}/cheapfake_{subset}_lowered_caps_data.joblib\")\n",
    "    df = pd.read_csv(f\"{DATA_DIR}/label_file_{subset}.csv\")\n",
    "    OBJ_FT_DIR = f\"{DATA_DIR}/{subset}/VisualObjectFeatures_b5\" # run extract_visual_features.py to get this\n",
    "    PRED_FT_DIR = f\"{DATA_DIR}/{subset}/VisualPredFeatures_b5\" # run extract_visual_features.py to get this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819e979-cdfd-4bf8-a38e-b72b5fe4c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data[\"231.jpg_small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c74ef-d39a-4d1c-8ca3-629f9b81237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(images_data.values())[229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3084b-3922-454b-aadb-ae55e2b8410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_data[231]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cae617-0c96-4573-9300-055c62e3d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db01d2-3414-4f2e-8a0f-898a75ebed73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval.validate_loss(images_data, caps_data, df, obj_ft_dir=OBJ_FT_DIR, pred_ft_dir=PRED_FT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf5e7f-6cd8-4905-b023-fd3221961d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval.validate_result(images_data, caps_data, df, obj_ft_dir=OBJ_FT_DIR, pred_ft_dir=PRED_FT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f5cf1-cc4a-4fd8-9594-99fefcc8f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.validate_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d698a-615f-4a99-a1c0-cdcc0dc828e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.validate_retrieval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f007b-d292-40ac-b119-cea3833b8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3131f-40f6-4c89-b092-e94bbdb8d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_size = 0\n",
    "for param in trainer.model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in trainer.model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b41174-229e-45d8-8122-4a604d507911",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79762a11-42f4-4211-bdba-6a6b1475cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainer.datatrain.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc5bd6-e098-410d-9b98-138018188bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020e701-b8d1-43ef-aa94-08b79cc3765b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd68b9f-7a84-422e-bd51-723a73a2effc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e5644c-f821-470f-98d7-7f35076c8a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11aeb0f-700c-4ce3-91c3-136323905727",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
